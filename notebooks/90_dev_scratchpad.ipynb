{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5927706d",
      "metadata": {},
      "source": [
        "# 90 – Dev Scratchpad\n",
        "\n",
        "This notebook is a **developer scratchpad** for the `ml_tabular` project.\n",
        "\n",
        "It is intentionally flexible and unpolished from a \"story\" point of view, but very\n",
        "structured from an **engineering** point of view. The goals are:\n",
        "\n",
        "- Give you a safe place to **experiment** with code, configs, datasets, and models\n",
        "- Provide a few **ready-made smoke tests** for key components\n",
        "- Make it easy to debug issues without editing your core package\n",
        "\n",
        "You can freely modify cells in this notebook during development. If it gets too messy,\n",
        "you can always reset it from version control.\n",
        "\n",
        "> Guiding principle: this notebook is **for you**, not for end users. Use it to move fast\n",
        "> and debug deeply, while keeping your main notebooks clean and narrative-focused."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d05b35a6",
      "metadata": {},
      "source": [
        "## 0. Setup & imports\n",
        "\n",
        "We enable autoreload so that edits to the `ml_tabular` package (and submodules) are picked\n",
        "up without restarting the kernel.\n",
        "\n",
        "We also import the key building blocks that you are most likely to poke at:\n",
        "\n",
        "- Config & paths helpers: `get_config`, `get_paths`\n",
        "- Logging helper: `get_logger`\n",
        "- Datasets: `TabularDataset`, `TimeSeriesSequenceDataset`\n",
        "- Models: `TabularMLP`\n",
        "- Training utilities: `train_one_epoch`, `evaluate`, `fit`, `EarlyStopping`\n",
        "- Optional MLOps helpers: MLflow utilities (if available)\n",
        "\n",
        "You can extend this section with any additional utilities you add later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f80851",
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ml_tabular import (\n",
        "    get_config,\n",
        "    get_paths,\n",
        "    get_logger,\n",
        "    TabularDataset,\n",
        "    TimeSeriesSequenceDataset,\n",
        "    TabularMLP,\n",
        "    train_one_epoch,\n",
        "    evaluate,\n",
        "    fit,\n",
        "    EarlyStopping,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from ml_tabular.mlops.mlflow_utils import (\n",
        "        is_mlflow_available,\n",
        "        mlflow_run,\n",
        "        log_params,\n",
        "        log_metrics,\n",
        "        log_artifact,\n",
        "    )\n",
        "    HAS_MLFLOW_UTILS = True\n",
        "except Exception:\n",
        "    HAS_MLFLOW_UTILS = False\n",
        "\n",
        "LOGGER = get_logger(__name__)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LOGGER.info(\"Scratchpad using device: %s\", DEVICE)\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "\n",
        "TABULAR_CONFIG = PROJECT_ROOT / \"configs\" / \"tabular\" / \"train_tabular_baseline.yaml\"\n",
        "TS_CONFIG = PROJECT_ROOT / \"configs\" / \"time_series\" / \"train_ts_baseline.yaml\"\n",
        "print(\"Tabular config:\", TABULAR_CONFIG)\n",
        "print(\"Time-series config:\", TS_CONFIG)\n",
        "\n",
        "print(\"Tabular config exists:\", TABULAR_CONFIG.exists())\n",
        "print(\"Time-series config exists:\", TS_CONFIG.exists())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f26c5a8",
      "metadata": {},
      "source": [
        "> **Tip:** If the config paths above print `False` for `exists`, either:\n",
        ">\n",
        "> - Adjust `TABULAR_CONFIG` / `TS_CONFIG` to match your layout, or\n",
        "> - Create the baseline configs from your template files before using this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8e0988",
      "metadata": {},
      "source": [
        "## 1. Quick config inspection\n",
        "\n",
        "This section is for quickly inspecting your config objects and confirming that environment\n",
        "variables / YAML are being applied as you expect.\n",
        "\n",
        "- Load tabular config (if present)\n",
        "- Print out key sections\n",
        "        \n",
        "- Inspect resolved paths\n",
        "\n",
        "You can freely tweak and re-run this cell as you iterate on config design."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d8b91fd",
      "metadata": {
        "tags": [
          "config"
        ]
      },
      "outputs": [],
      "source": [
        "if TABULAR_CONFIG.exists():\n",
        "    cfg_tab = get_config(config_path=TABULAR_CONFIG, env=\"dev\", force_reload=True)\n",
        "    paths_tab = get_paths(config_path=TABULAR_CONFIG, env=\"dev\", force_reload=True)\n",
        "\n",
        "    print(\"[TABULAR CONFIG]\")\n",
        "    print(\"env:\", cfg_tab.env)\n",
        "    print(\"log_level:\", cfg_tab.log_level)\n",
        "    print(\"experiment_name:\", cfg_tab.experiment_name)\n",
        "    print(\"paths:\", cfg_tab.paths)\n",
        "    print(\"training:\", cfg_tab.training)\n",
        "    print(\"resolved_paths:\", paths_tab)\n",
        "else:\n",
        "    print(\"Tabular config not found; skip or adjust TABULAR_CONFIG path.\")\n",
        "\n",
        "print(\"\\n---\\n\")\n",
        "\n",
        "if TS_CONFIG.exists():\n",
        "    cfg_ts = get_config(config_path=TS_CONFIG, env=\"dev\", force_reload=True)\n",
        "    paths_ts = get_paths(config_path=TS_CONFIG, env=\"dev\", force_reload=True)\n",
        "\n",
        "    print(\"[TIME-SERIES CONFIG]\")\n",
        "    print(\"env:\", cfg_ts.env)\n",
        "    print(\"log_level:\", cfg_ts.log_level)\n",
        "    print(\"experiment_name:\", cfg_ts.experiment_name)\n",
        "    print(\"paths:\", cfg_ts.paths)\n",
        "    print(\"training:\", cfg_ts.training)\n",
        "    print(\"time_series section:\", cfg_ts.to_dict().get(\"time_series\", {}))\n",
        "    print(\"resolved_paths:\", paths_ts)\n",
        "else:\n",
        "    print(\"Time-series config not found; skip or adjust TS_CONFIG path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c11d72",
      "metadata": {},
      "source": [
        "## 2. Tabular pipeline smoke test\n",
        "\n",
        "This is a **lightweight smoke test** for the tabular path:\n",
        "\n",
        "1. Load the baseline tabular config\n",
        "2. Load the configured CSV into a pandas DataFrame\n",
        "3. Create a `TabularDataset` and `DataLoader`\n",
        "4. Instantiate a small `TabularMLP`\n",
        "5. Run one forward pass to verify shapes and data wiring\n",
        "\n",
        "If anything breaks here, you can debug directly from within the notebook without touching\n",
        "your training scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb713258",
      "metadata": {
        "tags": [
          "tabular_smoke"
        ]
      },
      "outputs": [],
      "source": [
        "if not TABULAR_CONFIG.exists():\n",
        "    print(\"Tabular config missing; skipping tabular smoke test.\")\n",
        "else:\n",
        "    cfg_tab = get_config(config_path=TABULAR_CONFIG, env=\"dev\", force_reload=True)\n",
        "    paths_tab = get_paths(config_path=TABULAR_CONFIG, env=\"dev\", force_reload=True)\n",
        "    cfg_tab_dict = cfg_tab.to_dict()\n",
        "\n",
        "    tab_cfg = cfg_tab_dict.get(\"tabular\", {})\n",
        "    dataset_csv = tab_cfg.get(\"dataset_csv\")\n",
        "    if dataset_csv is None:\n",
        "        raise ValueError(\"tabular.dataset_csv not set in config.\")\n",
        "\n",
        "    data_path = paths_tab.data_dir / dataset_csv\n",
        "    print(\"Tabular data path:\", data_path)\n",
        "    assert data_path.exists(), f\"Dataset not found: {data_path}\"\n",
        "\n",
        "    df_tab = pd.read_csv(data_path)\n",
        "    print(\"Loaded tabular dataset:\")\n",
        "    display(df_tab.head())\n",
        "    print(\"Shape:\", df_tab.shape)\n",
        "\n",
        "    target_col = tab_cfg.get(\"target_column\")\n",
        "    feature_cols = tab_cfg.get(\"feature_columns\")\n",
        "    problem_type = tab_cfg.get(\"problem_type\", \"regression\")\n",
        "\n",
        "    print(\"Target column:\", target_col)\n",
        "    print(\"Feature columns:\", feature_cols)\n",
        "    print(\"Problem type:\", problem_type)\n",
        "\n",
        "    dataset_tab = TabularDataset.from_dataframe(\n",
        "        df_tab,\n",
        "        feature_columns=feature_cols,\n",
        "        target_column=target_col,\n",
        "        problem_type=problem_type,\n",
        "    )\n",
        "\n",
        "    print(\"Tabular dataset metadata:\", dataset_tab.metadata)\n",
        "\n",
        "    batch_size = cfg_tab.training.batch_size\n",
        "    loader_tab = DataLoader(dataset_tab, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    x_batch, y_batch = next(iter(loader_tab))\n",
        "    print(\"x_batch shape:\", x_batch.shape)\n",
        "    print(\"y_batch shape:\", y_batch.shape)\n",
        "\n",
        "    model_cfg = cfg_tab_dict.get(\"tabular_model\", {})\n",
        "    input_dim = x_batch.shape[1]\n",
        "    hidden_dims = model_cfg.get(\"hidden_dims\", [128, 64])\n",
        "    dropout = float(model_cfg.get(\"dropout\", 0.1))\n",
        "\n",
        "    num_classes = None\n",
        "    if problem_type == \"classification\":\n",
        "        num_classes = int(dataset_tab.metadata.get(\"num_classes\", 2))\n",
        "\n",
        "    model_tab = TabularMLP(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dims=hidden_dims,\n",
        "        output_dim=1 if problem_type == \"regression\" else num_classes,\n",
        "        dropout=dropout,\n",
        "        problem_type=problem_type,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model_tab(x_batch.to(DEVICE))\n",
        "    print(\"Forward pass OK – preds shape:\", preds.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3f8bca6",
      "metadata": {},
      "source": [
        "## 3. Time-series pipeline smoke test\n",
        "\n",
        "Similar to the tabular smoke test, but for the time-series path:\n",
        "\n",
        "1. Load the baseline time-series config\n",
        "2. Load the configured CSV\n",
        "3. Build a `TimeSeriesSequenceDataset`\n",
        "4. Inspect shapes for a few sequences\n",
        "\n",
        "You can extend this by plugging in a sequence model (e.g. GRU, TCN) and running a small\n",
        "training loop directly from here when debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d60bd74",
      "metadata": {
        "tags": [
          "ts_smoke"
        ]
      },
      "outputs": [],
      "source": [
        "if not TS_CONFIG.exists():\n",
        "    print(\"Time-series config missing; skipping time-series smoke test.\")\n",
        "else:\n",
        "    cfg_ts = get_config(config_path=TS_CONFIG, env=\"dev\", force_reload=True)\n",
        "    paths_ts = get_paths(config_path=TS_CONFIG, env=\"dev\", force_reload=True)\n",
        "    cfg_ts_dict = cfg_ts.to_dict()\n",
        "    ts_cfg = cfg_ts_dict.get(\"time_series\", {})\n",
        "\n",
        "    dataset_csv = ts_cfg.get(\"dataset_csv\")\n",
        "    if dataset_csv is None:\n",
        "        raise ValueError(\"time_series.dataset_csv not set in config.\")\n",
        "\n",
        "    data_path = paths_ts.data_dir / dataset_csv\n",
        "    print(\"Time-series data path:\", data_path)\n",
        "    assert data_path.exists(), f\"Dataset not found: {data_path}\"\n",
        "\n",
        "    df_ts = pd.read_csv(data_path)\n",
        "    print(\"Loaded time-series dataset:\")\n",
        "    display(df_ts.head())\n",
        "    print(\"Shape:\", df_ts.shape)\n",
        "\n",
        "    id_col = ts_cfg.get(\"id_column\")\n",
        "    time_col = ts_cfg[\"time_column\"]\n",
        "    target_col = ts_cfg[\"target_column\"]\n",
        "    feature_cols = ts_cfg.get(\"feature_columns\") or []\n",
        "    lookback = int(ts_cfg.get(\"lookback\", 24))\n",
        "    horizon = int(ts_cfg.get(\"horizon\", 1))\n",
        "\n",
        "    print(\"ID column:\", id_col)\n",
        "    print(\"Time column:\", time_col)\n",
        "    print(\"Target column:\", target_col)\n",
        "    print(\"Feature columns:\", feature_cols)\n",
        "    print(\"lookback:\", lookback, \"horizon:\", horizon)\n",
        "\n",
        "    df_ts[time_col] = pd.to_datetime(df_ts[time_col], errors=\"raise\")\n",
        "    if id_col is not None:\n",
        "        df_ts = df_ts.sort_values([id_col, time_col]).reset_index(drop=True)\n",
        "    else:\n",
        "        df_ts = df_ts.sort_values(time_col).reset_index(drop=True)\n",
        "\n",
        "    dataset_ts = TimeSeriesSequenceDataset.from_dataframe(\n",
        "        df_ts,\n",
        "        id_column=id_col,\n",
        "        time_column=time_col,\n",
        "        feature_columns=feature_cols,\n",
        "        target_column=target_col,\n",
        "        lookback=lookback,\n",
        "        horizon=horizon,\n",
        "    )\n",
        "\n",
        "    print(\"Time-series dataset metadata:\", dataset_ts.metadata)\n",
        "    print(\"Number of sequences:\", len(dataset_ts))\n",
        "\n",
        "    if len(dataset_ts) > 0:\n",
        "        x_seq, y_target = dataset_ts[0]\n",
        "        print(\"First seq X shape:\", x_seq.shape)\n",
        "        print(\"First seq y shape:\", y_target.shape)\n",
        "    else:\n",
        "        print(\"WARNING: dataset produced zero sequences – check lookback/horizon vs series length.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fbad904",
      "metadata": {},
      "source": [
        "## 4. Minimal training loop sanity check (tabular)\n",
        "\n",
        "This optional section runs a **very small training loop** on the tabular pipeline to ensure:\n",
        "\n",
        "- Loss decreases\n",
        "- `train_one_epoch` / `evaluate` / `fit` work end-to-end\n",
        "\n",
        "You can keep epochs tiny (e.g. 2–3) to make this fast and use it to debug training code\n",
        "without touching your main scripts.\n",
        "\n",
        "> If you don't want to run training from the notebook, just skip this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e003e9",
      "metadata": {
        "tags": [
          "tabular_train_sanity"
        ]
      },
      "outputs": [],
      "source": [
        "RUN_TRAINING_SANITY = False  # flip to True when you want to run this\n",
        "\n",
        "if RUN_TRAINING_SANITY and TABULAR_CONFIG.exists():\n",
        "    cfg_tab = get_config(config_path=TABULAR_CONFIG, env=\"dev\", force_reload=True)\n",
        "    paths_tab = get_paths(config_path=TABULAR_CONFIG, env=\"dev\", force_reload=True)\n",
        "    cfg_tab_dict = cfg_tab.to_dict()\n",
        "    tab_cfg = cfg_tab_dict.get(\"tabular\", {})\n",
        "\n",
        "    dataset_csv = tab_cfg[\"dataset_csv\"]\n",
        "    data_path = paths_tab.data_dir / dataset_csv\n",
        "    df_tab = pd.read_csv(data_path)\n",
        "\n",
        "    target_col = tab_cfg[\"target_column\"]\n",
        "    feature_cols = tab_cfg[\"feature_columns\"]\n",
        "    problem_type = tab_cfg.get(\"problem_type\", \"regression\")\n",
        "\n",
        "    dataset_tab = TabularDataset.from_dataframe(\n",
        "        df_tab,\n",
        "        feature_columns=feature_cols,\n",
        "        target_column=target_col,\n",
        "        problem_type=problem_type,\n",
        "    )\n",
        "\n",
        "    batch_size = cfg_tab.training.batch_size\n",
        "    loader_tab = DataLoader(dataset_tab, batch_size=batch_size, shuffle=True)\n",
        "    val_loader_tab = DataLoader(dataset_tab, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    import torch.nn as nn\n",
        "    from torch.optim import Adam\n",
        "\n",
        "    x_sample, _ = dataset_tab[0]\n",
        "    input_dim = x_sample.shape[0]\n",
        "    model_cfg = cfg_tab_dict.get(\"tabular_model\", {})\n",
        "    hidden_dims = model_cfg.get(\"hidden_dims\", [128, 64])\n",
        "    dropout = float(model_cfg.get(\"dropout\", 0.1))\n",
        "\n",
        "    num_classes = None\n",
        "    if problem_type == \"classification\":\n",
        "        num_classes = int(dataset_tab.metadata.get(\"num_classes\", 2))\n",
        "\n",
        "    model_tab = TabularMLP(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dims=hidden_dims,\n",
        "        output_dim=1 if problem_type == \"regression\" else num_classes,\n",
        "        dropout=dropout,\n",
        "        problem_type=problem_type,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    if problem_type == \"regression\":\n",
        "        loss_fn = nn.MSELoss()\n",
        "    else:\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    lr = cfg_tab.training.learning_rate\n",
        "    wd = getattr(cfg_tab.training, \"weight_decay\", 0.0)\n",
        "    optimizer = Adam(model_tab.parameters(), lr=lr, weight_decay=wd)\n",
        "\n",
        "    num_epochs = min(cfg_tab.training.num_epochs, 3)\n",
        "    early_stopping = EarlyStopping(patience=2, min_delta=1e-4, mode=\"min\")\n",
        "\n",
        "    history = fit(\n",
        "        model=model_tab,\n",
        "        train_loader=loader_tab,\n",
        "        val_loader=val_loader_tab,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_fn,\n",
        "        num_epochs=num_epochs,\n",
        "        device=DEVICE,\n",
        "        early_stopping=early_stopping,\n",
        "    )\n",
        "\n",
        "    print(\"History:\", history)\n",
        "else:\n",
        "    print(\"RUN_TRAINING_SANITY is False or tabular config missing; skipping training sanity check.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73e20829",
      "metadata": {},
      "source": [
        "## 5. MLflow smoke test (optional)\n",
        "\n",
        "If you have MLflow installed and configured, you can use this section to sanity-check\n",
        "your **`ml_tabular.mlops.mlflow_utils`** helpers:\n",
        "\n",
        "- Confirm that a run can be created\n",
        "- Log params / metrics / artifacts\n",
        "\n",
        "You can keep this test extremely simple (e.g., log a dummy metric and a text file) just to\n",
        "validate wiring.\n",
        "\n",
        "> If MLflow is not installed, this section will simply report that and do nothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4dcb6e",
      "metadata": {
        "tags": [
          "mlflow_smoke"
        ]
      },
      "outputs": [],
      "source": [
        "RUN_MLFLOW_SMOKE = False  # flip to True when you want to test MLflow wiring\n",
        "\n",
        "if RUN_MLFLOW_SMOKE and HAS_MLFLOW_UTILS and 'is_mlflow_available' in globals() and is_mlflow_available():\n",
        "    import os\n",
        "\n",
        "    tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\") or (PROJECT_ROOT / \"mlruns\").as_uri()\n",
        "    experiment_name = \"dev_scratchpad_smoke\"\n",
        "\n",
        "    dummy_text_path = PROJECT_ROOT / \"_tmp_mlflow_dummy.txt\"\n",
        "    dummy_text_path.write_text(\"Hello from ml_tabular dev scratchpad!\", encoding=\"utf-8\")\n",
        "\n",
        "    with mlflow_run(\n",
        "        enabled=True,\n",
        "        experiment_name=experiment_name,\n",
        "        run_name=\"scratchpad_smoke_test\",\n",
        "        tracking_uri=tracking_uri,\n",
        "        tags={\"context\": \"dev_scratchpad\"},\n",
        "    ):\n",
        "        log_params({\n",
        "            \"debug_param\": 123,\n",
        "            \"note\": \"Scratchpad MLflow smoke test\",\n",
        "        })\n",
        "\n",
        "        log_metrics({\n",
        "            \"dummy_metric\": 0.42,\n",
        "        })\n",
        "\n",
        "        log_artifact(dummy_text_path, artifact_path=\"scratchpad\")\n",
        "\n",
        "    print(\"MLflow smoke test completed. Check your tracking UI.\")\n",
        "elif RUN_MLFLOW_SMOKE:\n",
        "    print(\"MLflow utils not available or mlflow not installed; skipping MLflow smoke test.\")\n",
        "else:\n",
        "    print(\"RUN_MLFLOW_SMOKE is False; MLflow smoke test disabled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a578ba",
      "metadata": {},
      "source": [
        "## 6. Freeform scratch area\n",
        "\n",
        "Use the cells below as a **playground** for:\n",
        "\n",
        "- Quick one-off experiments\n",
        "- Debugging data issues\n",
        "- Prototyping model changes before wiring them into scripts\n",
        "- Manual profiling or benchmarking\n",
        "\n",
        "You can add more sections (with headings) as your workflow evolves. This notebook is meant\n",
        "to be **alive**, not frozen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c1a0320",
      "metadata": {
        "tags": [
          "playground"
        ]
      },
      "outputs": [],
      "source": [
        "# --- Playground cell ---\n",
        "# Write any ad-hoc experimentation code here.\n",
        "# Example: quick check of dtypes in a dataset, or inspecting a specific feature.\n",
        "\n",
        "print(\"Scratchpad ready. Add your dev code in this cell or below.\")\n",
        "\n",
        "# Example (commented out):\n",
        "# if TABULAR_CONFIG.exists():\n",
        "#     cfg_tab = get_config(config_path=TABULAR_CONFIG, env=\"dev\")\n",
        "#     paths_tab = get_paths(config_path=TABULAR_CONFIG, env=\"dev\")\n",
        "#     df_example = pd.read_csv(paths_tab.data_dir / cfg_tab.to_dict()[\"tabular\"][\"dataset_csv\"])\n",
        "#     print(df_example.dtypes)\n",
        "#     display(df_example.describe(include=\"all\").T)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
