{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ccdce9f3",
      "metadata": {},
      "source": [
        "# 11 – Time Series EDA & Window Design\n",
        "\n",
        "This notebook focuses on **exploratory data analysis (EDA)** and **window design** for time-series data using the `ml_tabular` template.\n",
        "\n",
        "We will:\n",
        "\n",
        "1. Load configuration and raw time-series data\n",
        "2. Inspect schema, coverage, and frequency\n",
        "3. Analyze target behaviour (trend, seasonality, volatility)\n",
        "4. Inspect missing timestamps and gaps\n",
        "5. Explore candidate window parameters (`lookback`, `horizon`, `stride`)\n",
        "6. Prototype windows with `TimeSeriesSequenceDataset`\n",
        "7. Export a **candidate window config** back to YAML\n",
        "\n",
        "The goal is to treat **windowing as an explicit design decision**, not a magic number in code. This notebook helps you:\n",
        "\n",
        "- Justify your choice of lookback/horizon\n",
        "- Understand whether you have enough history per series\n",
        "- Identify frequency / seasonality assumptions\n",
        "- Feed those decisions back into your configuration and pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d49641f4",
      "metadata": {},
      "source": [
        "## 0. Setup\n",
        "\n",
        "Assumptions:\n",
        "\n",
        "- Project installed (from repo root):\n",
        "\n",
        "  ```bash\n",
        "  pip install -e .[dev]\n",
        "  ```\n",
        "\n",
        "- Time-series baseline config exists at:\n",
        "\n",
        "  - `configs/time_series/train_ts_baseline.yaml`\n",
        "\n",
        "- `TimeSeriesSequenceDataset` is implemented and importable from `ml_tabular.torch.datasets.time_series`.\n",
        "\n",
        "We run this notebook from the **project root** so relative paths resolve correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1822fb62",
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ml_tabular import (\n",
        "    get_config,\n",
        "    get_paths,\n",
        "    get_logger,\n",
        "    TimeSeriesSequenceDataset,\n",
        ")\n",
        "\n",
        "LOGGER = get_logger(__name__)\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "CONFIG_PATH = PROJECT_ROOT / \"configs\" / \"time_series\" / \"train_ts_baseline.yaml\"\n",
        "assert CONFIG_PATH.exists(), f\"Config not found: {CONFIG_PATH}\"\n",
        "\n",
        "cfg = get_config(config_path=CONFIG_PATH, env=\"dev\", force_reload=True)\n",
        "paths = get_paths(config_path=CONFIG_PATH, env=\"dev\", force_reload=True)\n",
        "\n",
        "cfg_dict = cfg.to_dict()\n",
        "ts_cfg = cfg_dict.get(\"time_series\", {})\n",
        "ts_cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4991bf66",
      "metadata": {},
      "source": [
        "We assume `time_series` config fields similar to:\n",
        "\n",
        "```yaml\n",
        "time_series:\n",
        "  dataset_csv: \"timeseries.csv\"\n",
        "  id_column: \"series_id\"        # or null for single series\n",
        "  time_column: \"timestamp\"\n",
        "  target_column: \"y\"\n",
        "  feature_columns: [\"x1\", \"x2\", ...]\n",
        "  lookback: 24\n",
        "  horizon: 1\n",
        "  val_fraction: 0.2\n",
        "  # (optional) stride: 1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0205fb3",
      "metadata": {},
      "source": [
        "## 1. Load data\n",
        "\n",
        "We read the configured CSV and ensure key columns exist, then parse the time column and sort appropriately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b79cc60c",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_csv = ts_cfg[\"dataset_csv\"]\n",
        "data_path = paths.data_dir / dataset_csv\n",
        "assert data_path.exists(), f\"Dataset not found: {data_path}\"\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "LOGGER.info(\"Loaded dataset with shape: %s\", df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "748b19dd",
      "metadata": {
        "tags": [
          "columns_check"
        ]
      },
      "outputs": [],
      "source": [
        "id_col = ts_cfg.get(\"id_column\")  # may be None for single series\n",
        "time_col = ts_cfg[\"time_column\"]\n",
        "target_col = ts_cfg[\"target_column\"]\n",
        "feature_cols = ts_cfg.get(\"feature_columns\") or []\n",
        "\n",
        "print(\"ID column:\", id_col)\n",
        "print(\"Time column:\", time_col)\n",
        "print(\"Target column:\", target_col)\n",
        "print(\"Feature columns:\", feature_cols)\n",
        "\n",
        "missing = [c for c in [time_col, target_col] + feature_cols if c not in df.columns]\n",
        "print(\"Missing columns:\", missing)\n",
        "assert not missing, f\"Config references columns not found in dataset: {missing}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d42f961",
      "metadata": {
        "tags": [
          "parse_time"
        ]
      },
      "outputs": [],
      "source": [
        "df[time_col] = pd.to_datetime(df[time_col], errors=\"raise\")\n",
        "\n",
        "if id_col is not None:\n",
        "    df = df.sort_values([id_col, time_col]).reset_index(drop=True)\n",
        "else:\n",
        "    df = df.sort_values(time_col).reset_index(drop=True)\n",
        "\n",
        "df[[c for c in [id_col, time_col, target_col] if c is not None]].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a2603e6",
      "metadata": {},
      "source": [
        "## 2. Coverage and series overview\n",
        "\n",
        "We examine:\n",
        "\n",
        "- Number of series\n",
        "- Time coverage per series\n",
        "- Number of points per series\n",
        "\n",
        "        \n",
        "This helps us understand whether our planned lookback/horizon are realistic given per-series history length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5375131b",
      "metadata": {
        "tags": [
          "coverage"
        ]
      },
      "outputs": [],
      "source": [
        "if id_col is not None:\n",
        "    n_series = df[id_col].nunique()\n",
        "    print(\"Number of series:\", n_series)\n",
        "    coverage = df.groupby(id_col)[time_col].agg([\"min\", \"max\", \"count\"]).rename(\n",
        "        columns={\"min\": \"time_min\", \"max\": \"time_max\", \"count\": \"n_points\"}\n",
        "    )\n",
        "    coverage.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb3fda3",
      "metadata": {},
      "outputs": [],
      "source": [
        "if id_col is None:\n",
        "    print(\"Single series dataset.\")\n",
        "    print(\"Time range:\", df[time_col].min(), \"->\", df[time_col].max())\n",
        "    print(\"Number of points:\", len(df))\n",
        "else:\n",
        "    print(\"Global time range:\", df[time_col].min(), \"->\", df[time_col].max())\n",
        "    print(\"Total points:\", len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1fe9af7",
      "metadata": {},
      "source": [
        "> **Questions to ask:**\n",
        "> - Do all series have enough points to support your planned `lookback` and `horizon`?\n",
        "> - Are some series too short and likely to be dropped when windowing?\n",
        "> - Is the time coverage roughly consistent, or do some series start later/end earlier?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7813d9ec",
      "metadata": {},
      "source": [
        "## 3. Time index and frequency analysis\n",
        "\n",
        "We now inspect the **time step distribution** to understand the implicit sampling frequency:\n",
        "\n",
        "- Are timestamps regularly spaced (e.g., hourly, daily, minutely)?\n",
        "- Are there large gaps?\n",
        "- Is frequency consistent across series?\n",
        "\n",
        "This strongly influences **how you choose lookback/horizon**:\n",
        "\n",
        "- 24-step lookback at hourly resolution ≈ 1 day of history\n",
        "- 24-step lookback at daily resolution ≈ 24 days\n",
        "\n",
        "We’ll compute deltas in seconds and look at their distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de9489f9",
      "metadata": {
        "tags": [
          "deltas"
        ]
      },
      "outputs": [],
      "source": [
        "def compute_time_deltas(df: pd.DataFrame, time_col: str, id_col: str | None = None) -> pd.Series:\n",
        "    \"\"\"Compute time deltas (in seconds) between consecutive rows.\n",
        "\n",
        "    For multi-series data, deltas are computed **within each series** and concatenated.\n",
        "    \"\"\"\n",
        "    if id_col is None:\n",
        "        return df[time_col].diff().dropna().dt.total_seconds()\n",
        "    else:\n",
        "        deltas = []\n",
        "        for _, group in df.groupby(id_col, sort=False):\n",
        "            d = group[time_col].diff().dropna().dt.total_seconds()\n",
        "            deltas.append(d)\n",
        "        if not deltas:\n",
        "            return pd.Series(dtype=float)\n",
        "        return pd.concat(deltas, ignore_index=True)\n",
        "\n",
        "deltas_sec = compute_time_deltas(df, time_col=time_col, id_col=id_col)\n",
        "print(\"Number of deltas:\", len(deltas_sec))\n",
        "deltas_sec.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8878ca94",
      "metadata": {
        "tags": [
          "deltas_plot"
        ]
      },
      "outputs": [],
      "source": [
        "if len(deltas_sec) > 0:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(deltas_sec, bins=30, edgecolor=\"black\", alpha=0.7)\n",
        "    plt.xlabel(\"Delta between timestamps (seconds)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Distribution of time deltas\")\n",
        "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "    common_deltas = deltas_sec.value_counts().head(10)\n",
        "    print(\"Most common deltas (seconds):\")\n",
        "    display(common_deltas.to_frame(\"count\"))\n",
        "else:\n",
        "    print(\"Not enough points to compute time deltas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d70986e",
      "metadata": {},
      "source": [
        "> **Interpretation tips:**\n",
        "> - A single dominant delta (e.g., 3600 seconds) suggests a clear base frequency (hourly).\n",
        "> - Multiple modes may indicate irregular sampling or mixed frequencies.\n",
        "> - Large outliers in deltas suggest big gaps (e.g., outages, missing days)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a869fe3c",
      "metadata": {},
      "source": [
        "## 4. Missing timestamps and gaps\n",
        "\n",
        "We look for **large gaps** in the time series where:\n",
        "\n",
        "- Delta between consecutive timestamps exceeds some threshold\n",
        "- E.g., allowed frequency × 1.5\n",
        "\n",
        "This is especially important for forecasting models: large gaps might break stationarity assumptions or imply the need for interpolation or masking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5a9279",
      "metadata": {
        "tags": [
          "gaps"
        ]
      },
      "outputs": [],
      "source": [
        "if len(deltas_sec) > 0:\n",
        "    median_delta = deltas_sec.median()\n",
        "    threshold = median_delta * 1.5\n",
        "    large_gaps = deltas_sec[deltas_sec > threshold]\n",
        "\n",
        "    print(\"Median delta (sec):\", median_delta)\n",
        "    print(\"Gap threshold (sec):\", threshold)\n",
        "    print(\"Number of large gaps:\", len(large_gaps))\n",
        "\n",
        "    if len(large_gaps) > 0:\n",
        "        display(large_gaps.describe())\n",
        "else:\n",
        "    print(\"Skipping gap analysis; insufficient deltas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "816632f9",
      "metadata": {},
      "source": [
        "> **Actionable outcomes:**\n",
        "> - Decide whether to **interpolate**, **mask**, or **drop** segments around large gaps.\n",
        "> - Potentially add a **config flag** like `drop_large_gaps: true` or `max_gap_seconds` in `time_series` config for your data pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c630d4",
      "metadata": {},
      "source": [
        "## 5. Target behaviour: trend and seasonality\n",
        "\n",
        "We now look more closely at the target series:\n",
        "\n",
        "- Raw time-series plots for sample series\n",
        "- Rolling means / standard deviations\n",
        "- Simple seasonal patterns (e.g. day-of-week, hour-of-day) if applicable\n",
        "\n",
        "This helps justify the **lookback window**: you want enough history to capture relevant patterns (seasonality, trend) without exploding model complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4fd60cd",
      "metadata": {
        "tags": [
          "plot_series"
        ]
      },
      "outputs": [],
      "source": [
        "def plot_series(df_series: pd.DataFrame, time_col: str, target_col: str, title: str = \"\") -> None:\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.plot(df_series[time_col], df_series[target_col], marker=\".\", linestyle=\"-\", alpha=0.7)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(target_col)\n",
        "    plt.title(title or f\"Series: {target_col}\")\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if id_col is None:\n",
        "    plot_series(df, time_col, target_col, title=\"Target over time (single series)\")\n",
        "else:\n",
        "    # Plot a few random series\n",
        "    unique_ids = df[id_col].unique()\n",
        "    n_plot = min(3, len(unique_ids))\n",
        "    for sid in unique_ids[:n_plot]:\n",
        "        subset = df[df[id_col] == sid]\n",
        "        plot_series(subset, time_col, target_col, title=f\"Series {sid} – target over time\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a72d15e8",
      "metadata": {},
      "source": [
        "### 5.1 Rolling statistics\n",
        "\n",
        "We compute rolling mean and standard deviation to see how the **local level and volatility** change over time. This can influence:\n",
        "\n",
        "- Whether a **fixed lookback** is adequate\n",
        "- Whether we should consider **differencing** or **detrending**\n",
        "\n",
        "We’ll demo on a single series (or the single global series)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84b3159",
      "metadata": {
        "tags": [
          "rolling"
        ]
      },
      "outputs": [],
      "source": [
        "def plot_rolling(df_series: pd.DataFrame, time_col: str, target_col: str, window: int = 24) -> None:\n",
        "    s = df_series[target_col].astype(float)\n",
        "    roll_mean = s.rolling(window=window, min_periods=1).mean()\n",
        "    roll_std = s.rolling(window=window, min_periods=1).std()\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df_series[time_col], s, label=\"target\", alpha=0.5)\n",
        "    plt.plot(df_series[time_col], roll_mean, label=f\"rolling mean (window={window})\")\n",
        "    plt.fill_between(\n",
        "        df_series[time_col].values,\n",
        "        (roll_mean - roll_std).values,\n",
        "        (roll_mean + roll_std).values,\n",
        "        color=\"gray\",\n",
        "        alpha=0.2,\n",
        "        label=\"rolling ±1 std\",\n",
        "    )\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(target_col)\n",
        "    plt.title(\"Rolling statistics of target\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "example_series = df if id_col is None else df[df[id_col] == df[id_col].iloc[0]]\n",
        "plot_rolling(example_series, time_col, target_col, window=min(48, len(example_series)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5af9347",
      "metadata": {},
      "source": [
        "### 5.2 Simple seasonal patterns (optional)\n",
        "\n",
        "If your data has a clear base frequency (e.g. hourly, daily), you can inspect target by:\n",
        "\n",
        "- Hour of day\n",
        "- Day of week\n",
        "\n",
        "This helps identify whether `lookback` should span a full **daily or weekly season**.\n",
        "\n",
        "> These plots assume that such notions make sense for your data. If your timestamps are irregular or sparse, they may be less informative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b1ac521",
      "metadata": {
        "tags": [
          "seasonality"
        ]
      },
      "outputs": [],
      "source": [
        "series_for_seasonality = df.copy()\n",
        "series_for_seasonality[\"hour\"] = series_for_seasonality[time_col].dt.hour\n",
        "series_for_seasonality[\"dow\"] = series_for_seasonality[time_col].dt.dayofweek\n",
        "\n",
        "hourly = series_for_seasonality.groupby(\"hour\")[target_col].mean()\n",
        "dow = series_for_seasonality.groupby(\"dow\")[target_col].mean()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "axes[0].plot(hourly.index, hourly.values, marker=\"o\")\n",
        "axes[0].set_xlabel(\"Hour of day\")\n",
        "axes[0].set_ylabel(target_col)\n",
        "axes[0].set_title(\"Average target by hour\")\n",
        "axes[0].grid(True, linestyle=\"--\", alpha=0.4)\n",
        "\n",
        "axes[1].plot(dow.index, dow.values, marker=\"o\")\n",
        "axes[1].set_xlabel(\"Day of week (0=Mon)\")\n",
        "axes[1].set_ylabel(target_col)\n",
        "axes[1].set_title(\"Average target by day of week\")\n",
        "axes[1].grid(True, linestyle=\"--\", alpha=0.4)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "559c7170",
      "metadata": {},
      "source": [
        "> **Interpretation tips:**\n",
        "> - If the pattern repeats daily, you might want `lookback` ≥ 24 (hourly) or ≥ 7 (daily) to capture a full cycle.\n",
        "> - For multiple overlapping seasonalities (e.g. daily + weekly), you may need longer lookback or specialized architectures (e.g. seasonal encodings)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4adf4a78",
      "metadata": {},
      "source": [
        "## 6. Window design: exploring lookback & horizon\n",
        "\n",
        "We now focus on **window design**:\n",
        "\n",
        "- `lookback`: how many past time steps the model sees\n",
        "- `horizon`: how many future steps the model predicts\n",
        "- (Optional) `stride`: how far we move the window each time\n",
        "\n",
        "Design tradeoffs:\n",
        "\n",
        "- Larger lookback → more context, but more parameters and risk of overfitting\n",
        "- Longer horizon → more difficult prediction, may need more sophisticated model\n",
        "- Smaller stride → more training samples (but more correlation between samples)\n",
        "\n",
        "We’ll try a few candidate `(lookback, horizon)` pairs and inspect:\n",
        "\n",
        "- Number of training sequences generated\n",
        "- Sample shapes\n",
        "- Whether short series are dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc954701",
      "metadata": {
        "tags": [
          "window_candidates"
        ]
      },
      "outputs": [],
      "source": [
        "candidate_windows = [\n",
        "    {\"lookback\": int(ts_cfg.get(\"lookback\", 24)), \"horizon\": int(ts_cfg.get(\"horizon\", 1))},\n",
        "    {\"lookback\": int(ts_cfg.get(\"lookback\", 24)) * 2, \"horizon\": int(ts_cfg.get(\"horizon\", 1))},\n",
        "    {\"lookback\": int(ts_cfg.get(\"lookback\", 24)), \"horizon\": max(1, int(ts_cfg.get(\"horizon\", 1)) * 2)},\n",
        "]\n",
        "\n",
        "candidate_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1622e2a4",
      "metadata": {
        "tags": [
          "window_explore"
        ]
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "for win in candidate_windows:\n",
        "    lb = win[\"lookback\"]\n",
        "    hz = win[\"horizon\"]\n",
        "    try:\n",
        "        ds = TimeSeriesSequenceDataset.from_dataframe(\n",
        "            df,\n",
        "            id_column=id_col,\n",
        "            time_column=time_col,\n",
        "            feature_columns=feature_cols,\n",
        "            target_column=target_col,\n",
        "            lookback=lb,\n",
        "            horizon=hz,\n",
        "        )\n",
        "        n_seq = len(ds)\n",
        "        example_x, example_y = ds[0]\n",
        "        results.append({\n",
        "            \"lookback\": lb,\n",
        "            \"horizon\": hz,\n",
        "            \"n_sequences\": n_seq,\n",
        "            \"x_shape\": tuple(example_x.shape),\n",
        "            \"y_shape\": tuple(example_y.shape),\n",
        "        })\n",
        "    except Exception as exc:\n",
        "        LOGGER.warning(\"Failed to build dataset for (lookback=%d, horizon=%d): %s\", lb, hz, exc)\n",
        "        results.append({\n",
        "            \"lookback\": lb,\n",
        "            \"horizon\": hz,\n",
        "            \"n_sequences\": 0,\n",
        "            \"x_shape\": None,\n",
        "            \"y_shape\": None,\n",
        "        })\n",
        "\n",
        "pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5431f0cf",
      "metadata": {},
      "source": [
        "> **How to read this:**\n",
        "> - If `n_sequences` collapses to a very small number for a candidate, that window is probably too ambitious.\n",
        "> - Check that `x_shape` and `y_shape` match your expectations (e.g., `(lookback, n_features)` and `(horizon,)`).\n",
        "> - Choose a **primary** `(lookback, horizon)` based on a balance between context and dataset size."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9095442f",
      "metadata": {},
      "source": [
        "### 6.1 Visualizing a few windows\n",
        "\n",
        "To build intuition, we can visualize how windows look for a given `(lookback, horizon)`:\n",
        "\n",
        "- Plot the input sequence (past) and target (future) on the same axis\n",
        "- Show a few consecutive windows to see how they overlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d866f4b0",
      "metadata": {
        "tags": [
          "window_visualization"
        ]
      },
      "outputs": [],
      "source": [
        "chosen_lb = int(ts_cfg.get(\"lookback\", 24))\n",
        "chosen_hz = int(ts_cfg.get(\"horizon\", 1))\n",
        "\n",
        "ds_chosen = TimeSeriesSequenceDataset.from_dataframe(\n",
        "    df,\n",
        "    id_column=id_col,\n",
        "    time_column=time_col,\n",
        "    feature_columns=feature_cols,\n",
        "    target_column=target_col,\n",
        "    lookback=chosen_lb,\n",
        "    horizon=chosen_hz,\n",
        ")\n",
        "\n",
        "print(\"Chosen lookback:\", chosen_lb)\n",
        "print(\"Chosen horizon:\", chosen_hz)\n",
        "print(\"Number of sequences (chosen):\", len(ds_chosen))\n",
        "\n",
        "n_preview = min(3, len(ds_chosen))\n",
        "for idx in range(n_preview):\n",
        "    x_seq, y_target = ds_chosen[idx]\n",
        "    x_seq = x_seq.numpy()\n",
        "    y_target = y_target.numpy()\n",
        "\n",
        "    # For visualization, assume univariate target and use first feature if many\n",
        "    past = x_seq[:, 0]  # first feature\n",
        "    future = y_target\n",
        "\n",
        "    t_past = np.arange(len(past))\n",
        "    t_future = np.arange(len(past), len(past) + len(future))\n",
        "\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    plt.plot(t_past, past, marker=\"o\", label=\"input (feature 0)\")\n",
        "    plt.plot(t_future, future, marker=\"x\", label=\"target future\")\n",
        "    plt.xlabel(\"Relative time index\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.title(f\"Window #{idx} – lookback={chosen_lb}, horizon={chosen_hz}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663a2434",
      "metadata": {},
      "source": [
        "> This visualization helps you see exactly what the model will observe and what it is asked to predict, using your chosen window configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a52a4d55",
      "metadata": {},
      "source": [
        "## 7. Export a candidate window configuration\n",
        "\n",
        "Based on the EDA and window exploration, you can now record your decisions in a small YAML file, e.g.:\n",
        "\n",
        "- Confirmed `lookback` and `horizon`\n",
        "- Optional `stride`\n",
        "- Notes on frequency / seasonality\n",
        "\n",
        "You can then merge this into your main `train_ts_baseline.yaml` or keep it as a separate profile. Below is a helper to write a **candidate** config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d81be35a",
      "metadata": {
        "tags": [
          "export_window_config"
        ]
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "window_config = {\n",
        "    \"lookback\": chosen_lb,\n",
        "    \"horizon\": chosen_hz,\n",
        "    # You can add stride or other options if your dataset supports it\n",
        "    \"stride\": int(ts_cfg.get(\"stride\", 1)),\n",
        "    # Free-form notes to remind future-you why you chose these values\n",
        "    \"notes\": {\n",
        "        \"frequency_hint\": \"e.g., hourly/daily – infer from deltas_sec distribution\",\n",
        "        \"seasonality_considered\": \"e.g., daily/weekly; see section 5.2 plots\",\n",
        "        \"design_rationale\": \"describe why this lookback/horizon are appropriate given data coverage\",\n",
        "    },\n",
        "}\n",
        "\n",
        "output_config_path = PROJECT_ROOT / \"configs\" / \"time_series\" / \"time_series_windows_candidate.yaml\"\n",
        "output_config_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with output_config_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.safe_dump(window_config, f, sort_keys=False)\n",
        "\n",
        "LOGGER.info(\"Wrote candidate time-series window config to: %s\", output_config_path)\n",
        "output_config_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7dbc0b7",
      "metadata": {},
      "source": [
        "## 8. Summary\n",
        "\n",
        "In this notebook, you:\n",
        "\n",
        "- Loaded time-series config and data using the same configuration system as your training code\n",
        "- Analyzed sampling frequency and time coverage per series\n",
        "- Inspected missing timestamps and large gaps\n",
        "- Explored target behaviour via raw plots, rolling stats, and simple seasonal patterns\n",
        "- Experimented with different `(lookback, horizon)` window designs using `TimeSeriesSequenceDataset`\n",
        "- Visualized example windows to sanity-check model inputs and targets\n",
        "- Exported a **candidate window configuration** to YAML for use in training scripts\n",
        "\n",
        "This makes your time-series modelling process **explicit, reproducible, and defensible**:\n",
        "\n",
        "- Window choices are backed by EDA, not guesswork\n",
        "- Config and code remain in sync\n",
        "- Notebooks tell a coherent story to reviewers and hiring managers about how you think about temporal data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
