{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eab9d079",
      "metadata": {},
      "source": [
        "# Tabular Quickstart: ml_tabular Template\n",
        "\n",
        "This notebook shows how to use the **ml_tabular** template end-to-end for a small tabular problem:\n",
        "\n",
        "1. Load configuration from a YAML file\n",
        "2. Inspect the dataset\n",
        "3. Build PyTorch `DataLoader`s using the template's `TabularDataset`\n",
        "4. Define a `TabularMLP` model via `TabularMLPConfig`\n",
        "5. Train and evaluate using the shared `fit` / `evaluate` utilities\n",
        "6. (Optional) Enable MLflow experiment tracking\n",
        "\n",
        "The goal is to demonstrate **how the pieces fit together**, not to get a state-of-the-art model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1409dc",
      "metadata": {},
      "source": [
        "## 0. Prerequisites\n",
        "\n",
        "This notebook assumes:\n",
        "\n",
        "- You have installed this project in your environment (e.g. from the repo root):\n",
        "\n",
        "  ```bash\n",
        "  pip install -e .[dev,mlops]\n",
        "  ```\n",
        "\n",
        "- You are running this notebook from the project root (or you adjust relative paths accordingly).\n",
        "- You have a baseline config at `configs/tabular/train_tabular_baseline.yaml`.\n",
        "\n",
        "If you followed the template, that config should already exist and point to a small CSV under `data/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3017e3fe",
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from ml_tabular import (\n",
        "    AppConfig,\n",
        "    PathsConfig,\n",
        "    get_config,\n",
        "    get_paths,\n",
        "    get_logger,\n",
        "    TabularDataset,\n",
        "    TabularMLP,\n",
        "    TabularMLPConfig,\n",
        "    train_one_epoch,\n",
        "    evaluate,\n",
        "    fit,\n",
        "    EarlyStopping,\n",
        ")\n",
        "\n",
        "LOGGER = get_logger(__name__)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LOGGER.info(\"Using device: %s\", DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18031216",
      "metadata": {},
      "source": [
        "## 1. Load configuration\n",
        "\n",
        "We load the **tabular baseline config** from YAML using the shared `get_config` helper.\n",
        "\n",
        "This config controls:\n",
        "- Paths (data, models)\n",
        "- Training hyperparameters (batch size, epochs, learning rate, etc.)\n",
        "- Tabular-specific settings (target column, feature columns, task type, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31dfda2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path.cwd()\n",
        "CONFIG_PATH = PROJECT_ROOT / \"configs\" / \"tabular\" / \"train_tabular_baseline.yaml\"\n",
        "\n",
        "assert CONFIG_PATH.exists(), f\"Config not found: {CONFIG_PATH}\"\n",
        "\n",
        "cfg: AppConfig = get_config(config_path=CONFIG_PATH, env=\"dev\", force_reload=True)\n",
        "paths: PathsConfig = get_paths(config_path=CONFIG_PATH, env=\"dev\", force_reload=True)\n",
        "\n",
        "cfg_dict = cfg.to_dict()\n",
        "cfg_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f25f38cb",
      "metadata": {},
      "source": [
        "You should see a nested dictionary that includes at least:\n",
        "\n",
        "- `env`, `experiment_name`, `log_level`\n",
        "- `paths` → `data_dir`, `models_dir`, etc.\n",
        "- `training` → `batch_size`, `num_epochs`, `learning_rate`, `early_stopping`, ...\n",
        "- `tabular` → `dataset_csv`, `target_column`, `feature_columns`, `task_type`, `num_classes`, ...\n",
        "\n",
        "We can quickly inspect the tabular sub-config:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67648d39",
      "metadata": {},
      "outputs": [],
      "source": [
        "tab_cfg = cfg_dict.get(\"tabular\", {})\n",
        "tab_cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75285746",
      "metadata": {},
      "source": [
        "## 2. Inspect the dataset\n",
        "\n",
        "We'll load the CSV referenced in the config and do a quick sanity check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f36c8736",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_csv = tab_cfg[\"dataset_csv\"]\n",
        "data_path = paths.data_dir / dataset_csv\n",
        "assert data_path.exists(), f\"Dataset not found: {data_path}\"\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "LOGGER.info(\"Loaded dataset with shape %s\", df.shape)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c05de988",
      "metadata": {},
      "source": [
        "We'll also verify that the columns referenced in config actually exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71c4c0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_columns = tab_cfg.get(\"feature_columns\") or []\n",
        "target_column = tab_cfg[\"target_column\"]\n",
        "\n",
        "missing_features = [c for c in feature_columns if c not in df.columns]\n",
        "missing_target = target_column not in df.columns\n",
        "\n",
        "        \n",
        "print(\"Feature columns:\", feature_columns)\n",
        "print(\"Target column:\", target_column)\n",
        "print(\"Missing features:\", missing_features)\n",
        "print(\"Missing target?\", missing_target)\n",
        "\n",
        "assert not missing_features, \"Config references feature columns not in dataset.\"\n",
        "assert not missing_target, \"Config references a target column not in dataset.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67bcd530",
      "metadata": {},
      "source": [
        "## 3. Build PyTorch DataLoaders\n",
        "\n",
        "We now turn the `pandas.DataFrame` into a `TabularDataset`, and then into `DataLoader`s for training and validation.\n",
        "\n",
        "The `TabularDataset` handles:\n",
        "- Column selection\n",
        "- Conversion to float tensors\n",
        "- Simple metadata (feature names, target name, etc.)\n",
        "\n",
        "We’ll use a simple **train/validation split** for this quickstart. For real projects you might:\n",
        "- Use stratified splits\n",
        "- Use cross-validation\n",
        "- Or reuse pre-split train/val files per config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2015abe8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_size = tab_cfg.get(\"val_size\", 0.2)\n",
        "random_seed = cfg.training.random_seed if hasattr(cfg, \"training\") else 42\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=test_size,\n",
        "    random_state=random_seed,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "LOGGER.info(\"Train shape: %s, Val shape: %s\", train_df.shape, val_df.shape)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe966e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = TabularDataset.from_dataframe(\n",
        "    train_df,\n",
        "    feature_columns=feature_columns,\n",
        "    target_column=target_column,\n",
        ")\n",
        "\n",
        "val_ds = TabularDataset.from_dataframe(\n",
        "    val_df,\n",
        "    feature_columns=feature_columns,\n",
        "    target_column=target_column,\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", len(train_ds))\n",
        "print(\"Val samples:\", len(val_ds))\n",
        "print(\"Metadata:\", train_ds.metadata)\n",
        "\n",
        "x0, y0 = train_ds[0]\n",
        "print(\"Single sample X shape:\", x0.shape)\n",
        "print(\"Single sample y shape:\", y0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c6a038a",
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = cfg.training.batch_size if hasattr(cfg, \"training\") else 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "batch_x, batch_y = next(iter(train_loader))\n",
        "print(\"Batch X shape:\", batch_x.shape)\n",
        "print(\"Batch y shape:\", batch_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f72707e",
      "metadata": {},
      "source": [
        "## 4. Define `TabularMLP` via `TabularMLPConfig`\n",
        "\n",
        "We now set up the MLP model. We infer:\n",
        "\n",
        "- `input_dim` from the number of features\n",
        "- `output_dim` and `task_type` from the tabular config (binary, multiclass, or regression)\n",
        "\n",
        "The idea is that **model config** is explicit, and driven by the config file + dataset metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d06a082",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_features = len(feature_columns)\n",
        "task_type = tab_cfg.get(\"task_type\", \"binary\")\n",
        "num_classes = tab_cfg.get(\"num_classes\", 1)\n",
        "\n",
        "if task_type == \"binary\" or task_type == \"regression\":\n",
        "    output_dim = 1\n",
        "elif task_type == \"multiclass\":\n",
        "    output_dim = int(num_classes)\n",
        "else:\n",
        "    raise ValueError(f\"Unknown task_type in config: {task_type}\")\n",
        "\n",
        "hidden_dims = tab_cfg.get(\"hidden_dims\") or [64, 32]\n",
        "\n",
        "model_cfg = TabularMLPConfig(\n",
        "    input_dim=num_features,\n",
        "    hidden_dims=hidden_dims,\n",
        "    output_dim=output_dim,\n",
        "    activation=\"relu\",\n",
        "    dropout=float(tab_cfg.get(\"dropout\", 0.1)),\n",
        "    batch_norm=bool(tab_cfg.get(\"batch_norm\", False)),\n",
        "    layer_norm=bool(tab_cfg.get(\"layer_norm\", False)),\n",
        "    task_type=task_type,\n",
        ")\n",
        "\n",
        "model = TabularMLP(model_cfg).to(DEVICE)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e761487b",
      "metadata": {},
      "source": [
        "## 5. Train and evaluate with shared training utilities\n",
        "\n",
        "We can now:\n",
        "\n",
        "1. Define an optimizer and loss function\n",
        "2. Optionally configure **early stopping**\n",
        "3. Call `fit(...)` to run the training loop using the shared utilities from the template.\n",
        "\n",
        "This mirrors what your `train_tabular_mlp.py` script does, but in an interactive setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337ff6b5",
      "metadata": {
        "tags": [
          "training"
        ]
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "learning_rate = cfg.training.learning_rate if hasattr(cfg, \"training\") else 1e-3\n",
        "weight_decay = getattr(cfg.training, \"weight_decay\", 0.0) if hasattr(cfg, \"training\") else 0.0\n",
        "num_epochs = cfg.training.num_epochs if hasattr(cfg, \"training\") else 5\n",
        "\n",
        "if task_type == \"regression\":\n",
        "    loss_fn = nn.MSELoss()\n",
        "else:\n",
        "    # For binary: BCEWithLogitsLoss, for multiclass: CrossEntropyLoss on logits\n",
        "    if task_type == \"binary\":\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# Optional: early stopping based on validation loss\n",
        "es_cfg = cfg_dict.get(\"training\", {}).get(\"early_stopping\", {})\n",
        "if es_cfg:\n",
        "    early_stopping = EarlyStopping(\n",
        "        patience=int(es_cfg.get(\"patience\", 5)),\n",
        "        min_delta=float(es_cfg.get(\"min_delta\", 1e-4)),\n",
        "        mode=es_cfg.get(\"mode\", \"min\"),\n",
        "    )\n",
        "else:\n",
        "    early_stopping = None\n",
        "\n",
        "history = fit(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn,\n",
        "    num_epochs=num_epochs,\n",
        "    device=DEVICE,\n",
        "    early_stopping=early_stopping,\n",
        ")\n",
        "\n",
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d0f958",
      "metadata": {},
      "source": [
        "You should see `train_losses` and `val_losses` over epochs. Let’s plot them quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc7be80",
      "metadata": {
        "tags": [
          "plot"
        ]
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_losses = history[\"train_losses\"]\n",
        "val_losses = history[\"val_losses\"]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_losses, marker=\"o\", label=\"train\")\n",
        "plt.plot(val_losses, marker=\"o\", label=\"val\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b2c0c76",
      "metadata": {},
      "source": [
        "## 6. Save model artifacts\n",
        "\n",
        "Finally, we save the trained model to the `models` directory defined by the config.\n",
        "\n",
        "This mirrors what your CLI script does, but gives you full control in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ff5a22",
      "metadata": {
        "tags": [
          "save"
        ]
      },
      "outputs": [],
      "source": [
        "paths.models_dir.mkdir(parents=True, exist_ok=True)\n",
        "model_path = paths.models_dir / f\"tabular_mlp_{cfg.experiment_name}.pt\"\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"model_cfg\": model_cfg.model_dump(),\n",
        "    \"config\": cfg_dict,\n",
        "}, model_path)\n",
        "\n",
        "LOGGER.info(\"Saved model to: %s\", model_path)\n",
        "model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22529852",
      "metadata": {},
      "source": [
        "## 7. (Optional) Enable MLflow tracking\n",
        "\n",
        "If you installed the `mlops` extra and set up MLflow, you can wrap training with the template's MLflow helper.\n",
        "\n",
        "This section is optional; comment it out if you don't have MLflow configured yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52f39392",
      "metadata": {
        "tags": [
          "mlflow",
          "optional"
        ]
      },
      "outputs": [],
      "source": [
        "from ml_tabular.mlops.mlflow_utils import (\n",
        "    is_mlflow_available,\n",
        "    mlflow_run,\n",
        "    log_params,\n",
        "    log_metrics,\n",
        "    log_artifact,\n",
        ")\n",
        "\n",
        "if is_mlflow_available():\n",
        "    import mlflow\n",
        "\n",
        "    tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\") or (paths.base_dir / \"mlruns\").as_uri()\n",
        "    experiment_name = cfg.experiment_name\n",
        "\n",
        "    with mlflow_run(\n",
        "        enabled=True,\n",
        "        experiment_name=experiment_name,\n",
        "        run_name=\"tabular_quickstart\",\n",
        "        tracking_uri=tracking_uri,\n",
        "        tags={\"template\": \"ml_tabular\", \"notebook\": \"00_tabular_quickstart\"},\n",
        "    ):\n",
        "        # Log high-level config and hyperparameters\n",
        "        log_params({\n",
        "            \"task_type\": task_type,\n",
        "            \"input_dim\": num_features,\n",
        "            \"hidden_dims\": hidden_dims,\n",
        "            \"output_dim\": output_dim,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"num_epochs\": num_epochs,\n",
        "        })\n",
        "\n",
        "        # Re-run a short training just for demonstration\n",
        "        model2 = TabularMLP(model_cfg).to(DEVICE)\n",
        "        optimizer2 = Adam(model2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "        history2 = fit(\n",
        "            model=model2,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            optimizer=optimizer2,\n",
        "            loss_fn=loss_fn,\n",
        "            num_epochs=3,\n",
        "            device=DEVICE,\n",
        "            early_stopping=None,\n",
        "        )\n",
        "\n",
        "        # Log final metrics\n",
        "        log_metrics({\n",
        "            \"final_train_loss\": float(history2[\"train_losses\"][-1]),\n",
        "            \"final_val_loss\": float(history2[\"val_losses\"][-1]),\n",
        "        })\n",
        "\n",
        "        # Log the previously saved model as an artifact\n",
        "        if model_path.exists():\n",
        "            log_artifact(model_path, artifact_path=\"models\")\n",
        "else:\n",
        "    print(\"MLflow not available; skipping MLflow tracking demo.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc911136",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this quickstart, you:\n",
        "\n",
        "- Loaded configuration via a strongly-typed `AppConfig`\n",
        "- Used `PathsConfig` to resolve data and model directories\n",
        "- Built a `TabularDataset` and `DataLoader`s from a CSV\n",
        "- Defined a `TabularMLP` using `TabularMLPConfig`\n",
        "- Trained the model using shared `fit` / `train_one_epoch` utilities\n",
        "- Saved model artifacts and (optionally) logged them to MLflow\n",
        "\n",
        "This demonstrates the **end-to-end story** your template is designed to tell: from config-driven setup, through a clean data/model/training stack, to reproducible artifacts and optional experiment tracking."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
